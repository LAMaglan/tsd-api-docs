
## Data pipelines

The file API provides services for on-the-fly stream processing based on custom Content-Type headers. For example, if a client uploads a `tar.gz` archive, it can request that the API decompress and restore the archive on-the-fly. This means that data will be stored as the original folder on disk, in the project area.

The API does this type of processing in an asynchronous manner, so clients can implement their own asynchronous data pipelines and connect it to the API, so that the data processing, upload, and storage is done in a non-blocking way end-to-end. A client can, therefore, compose a unix-style pipeline as such: `tar | gz | HTTPS POST (Transfer-Encoding: chunked) | gunzip | tar`, where each step will be done in an incremental way.

An example client that implements data pipelines for all the API stream processing services is the `tsd-api-client`. Ask `tsd-drift@usit.uio.no` for more info about this client application.

### 1. Outline

_Alpha. Breaking changes likely._

The API has the following stream processing services, each requested with the corresponding custom Content-Type header:

```
For files
=========
Custom Content-Type     |   API processing
-------------------     |   --------------
application/gz          |   gunzip
application/aes         |   aes decryption
application/gz.aes      |   aes decryption, gunzip

For directories
===============
Custom Content-Type     |   API processing
-------------------     |   --------------
application/tar         |   restore tar
application/tar.gz      |   gunzip, restore tar
application/tar.aes     |   aes decryption, restore tar
application/tar.gz.aes  |   aes decryption, gunzip, restore tar
```

On the client side, these data transformations have to be performed in the order specified within the custom Content-Types in the table. Any other order will result in an error in the API, and therefore a failed upload.

### 2. AES encryption

_Experimental. Expect breaking changes_.

Clients have the option to encrypt data with openssl AES 256 CBC and request that the API decrypt data before storing it to disk.

AES is a symmetric encryption scheme which supports streaming encryption and decryption. Because it is a symmetric scheme, decryption in the API requires that the encryption secret, generated by the client, be accessible when data processing begins. To accomplish this safely, we use asymmetric PGP encryption to encrypt the AES symmetric secret, and transfer the encrypted symmetric secret to the API in the HTTP request as a header.

A summary of the steps:

* client generates a secret
* feeds this secret into the AES encryption algorithm
* uses the API's PGP public key to encrypt the secret
* base64 encodes the encrypted secret
* places this encoded, encrypted secret in an HTTP header called `Aes-Key`
* starts the HTTP request

An example, using curl:

```bash
export PW=$(openssl rand -base64 10)
export ENCPW=$(echo $PW | gpg -r <recipient> --encrypt | openssl base64 -A)
echo 'hello world' | openssl enc -aes-256-cbc -a -pass file:<( echo $PW ) > example.aes
curl --data-binary @example.aes \
    https://test.api.tsd.usit.no/v1/p11/files/stream \
    -H "Content-Type: application/aes" \
    -H "Filename: somename.txt" \
    -H "Aes-Key: $ENCPW" \
    -H "Authorization: Bearer $token"
```

The API also supports another way of using AES: you can generate your own encryption key and initialisation vector, PGP encrypt the encryption key, and supply both explicitly in the HTTP request:

```bash
# base64 encoded
openssl enc -aes-256-cbc -a -iv ${hex_aes_iv} -K ${hex_aes_key} > example.aes
# or binary:
openssl enc -aes-256-cbc -iv ${hex_aes_iv} -K ${hex_aes_key} > example.aes
# then specifying the use of IV explicitly
curl --data-binary @example.aes \
    https://test.api.tsd.usit.no/v1/p11/files/stream \
    -H "Content-Type: application/aes" \
    -H "Filename: somename.txt" \
    -H "Aes-Key: $KEY" \
    -H "Aes-Iv: $IV" \
    -H "Authorization: Bearer $token"
```
